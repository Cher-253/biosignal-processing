{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biosignal Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves to process biosingal data collected from Emaptica4.\n",
    "```\n",
    "user_id:\n",
    "    eda.json\n",
    "    hr.json\n",
    "    \n",
    "# Inside a eda.json\n",
    "    session_id: 123 #in case we have multiple data by the same user\n",
    "    user_id: 478\n",
    "    tags: [\"pilot\", \"bio\", \"time-series\"]  # time-series tells us to expect a \"data\" key\n",
    "    name: \"EDA\"\n",
    "    description: \"Electrodermal activity\"\n",
    "    channels: 1\n",
    "    sampling_frequency: 3 #Hertz\n",
    "    units: \"microsiemens\"\n",
    "    ... # any other metadata\n",
    "    timestamp: 12301923012390 #unix\n",
    "    data: [1, 2, 3, 4, ..., 100900]\n",
    "    \n",
    "# Inside video.json\n",
    "    session_id: 123 #in case we have multiple data sessions with the same user\n",
    "    user_id: 478\n",
    "    tags: [\"pilot\", \"video\", \"resource\"] # resource tells us to expect a \"url\" key\n",
    "    name: \"SC\"\n",
    "    description: \"Screencapture of user screen\"\n",
    "    ...\n",
    "    timestamp: 12301923012390 #unix\n",
    "    url: \"adjadllkf.mp4\"\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save json Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_jsonfile(name, data):\n",
    "    #file = name + \".json\" #name is a string\n",
    "    with open(name, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    print(\"File saved!\", name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bio_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".csv files in this archive are in the following format:\n",
    "The first row is the initial time of the session expressed as unix timestamp in UTC.\n",
    "The second row is the sample rate expressed in Hz.\n",
    "\n",
    "### EDA.csv\n",
    "Data from the electrodermal activity sensor expressed as microsiemens (Î¼S).\n",
    "\n",
    "### HR.csv\n",
    "Average heart rate extracted from the BVP signal.The first row is the initial time of the session expressed as unix timestamp in UTC.\n",
    "The second row is the sample rate expressed in Hz.\n",
    "\n",
    "### Format of csv files\n",
    "userID_sessionID_type.csv    \n",
    "e.g: 25_0_HR.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "* Need to generalize the following code to create specific folder under user folder\n",
    "* code should automatically generate sessionID, userID, and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved! data/users/HR.json\n",
      "File saved! data/users/EDA.json\n"
     ]
    }
   ],
   "source": [
    "BIO_ROOT = \"data/biosignals/\"\n",
    "USER_ROOT = \"data/users/\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# create .json file from csv files\n",
    "def create_bio_json(bioName, sessionID, userID, name, sampFreq, timestamp, data):\n",
    "    unit = \"\"\n",
    "    description = \"\"\n",
    "    if bioName == \"HR\":\n",
    "        unit = \"bpm\"\n",
    "        description = \"Heart rate\"\n",
    "    if bioName == \"EDA\":\n",
    "        unit = \"microsiemens\"\n",
    "        description = \"Electrodermal data\"\n",
    "    tags = [\"bio\", \"time-series\"]\n",
    "    data = {\"sessionID\": sessionID, \\\n",
    "              \"userID\": userID, \\\n",
    "              \"tags\": tags, \\\n",
    "              \"name\": name, \\\n",
    "              \"description\": description, \\\n",
    "              \"sampling_frequency\": sampFreq, \\\n",
    "              \"timestamp\": timestamp, \\\n",
    "              \"unit\": unit, \\\n",
    "              \"data\": data \\\n",
    "             }\n",
    "    filePath = USER_ROOT + bioName + \".json\"\n",
    "    # print(filePath)\n",
    "    save_jsonfile(filePath, data)\n",
    "    \n",
    "\n",
    "# save the csv file into a .json file of the same name\n",
    "def grab_and_save(filename):\n",
    "    data = []\n",
    "    file = BIO_ROOT + filename\n",
    "    name = filename[:-4]\n",
    "    #print(file)\n",
    "    with open(file) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        timestamp = next(csvreader)[0]\n",
    "        #print(timestamp)\n",
    "        sampling_rate = next(csvreader)[0]\n",
    "        #print(sampling_rate)\n",
    "        for row in csvreader:\n",
    "            data.append(row[0])\n",
    "    # TODO: modify parameters\n",
    "    # sessionID, userID, tags, name, description, sampFreq, data\n",
    "    create_bio_json(name, 0, 25, \"cesar\",\\\n",
    "                    sampling_rate, timestamp, data)\n",
    "    #create json file and save data into json file\n",
    "\n",
    "# Iterate through the csv files in BIO_ROOT and generate json objects   \n",
    "directory = os.fsencode(BIO_ROOT)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".csv\"):\n",
    "        #print(filename[:-4])\n",
    "        grab_and_save(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Data\n",
    "\n",
    "Video data are uploaded in data/videos. Coded csv files live in data/videos/coded. We will be aligning the video with biosignals using unix timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1530213266.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEO_ROOT = \"data/videos/\"\n",
    "\n",
    "import datetime, platform\n",
    "\n",
    "# get the timestamp of the video\n",
    "def get_video_timestamp(userID):\n",
    "    uid = str(userID)\n",
    "    raw_video = VIDEO_ROOT + uid + \"H\" + \".MOV\"\n",
    "    if platform.system() == \"Darwin\":\n",
    "        posix_time = os.stat(raw_video).st_birthtime\n",
    "#         t = datetime.datetime.fromtimestamp(posix_time).strftime(\n",
    "#                 '%Y-%m-%dT%H:%M:%SZ')\n",
    "        # print(t)\n",
    "        # print(posix_time)\n",
    "        # session = os.path.basename(raw_video).split('.')[0]\n",
    "        # url = \"/\" + raw_video\n",
    "        # print(url)\n",
    "        return posix_time + 77 #just for this time. Adjust for delayed save of screencast\n",
    "\n",
    "# For this specific subject run\n",
    "get_video_timestamp(25)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biosignal + Video Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average HR for Getting Started:\n",
      "70.63698598130843\n",
      "Average EDA for Getting Started:\n",
      "2.176238580023365\n",
      "Average HR for Success:\n",
      "95.77905405405407\n",
      "Average EDA for Success:\n",
      "2.7984748547297285\n",
      "Average HR for Encountering Difficulties:\n",
      "110.53377777777781\n",
      "Average EDA for Encountering Difficulties:\n",
      "3.026694483333332\n",
      "Average HR for Dealing with Difficulties:\n",
      "94.03788321167876\n",
      "Average EDA for Dealing with Difficulties:\n",
      "2.8561579133211685\n"
     ]
    }
   ],
   "source": [
    "CODED_ROOT = \"data/videos/coded/\"\n",
    "from pprint import pprint\n",
    "\n",
    "# calculates the difference in terms of unix timestamp (seconds) between the video and the biosignals.\n",
    "# If difference is positive, then video is taken after the biosignal\n",
    "# If difference is negative, then video is taken before the biosignal\n",
    "def timestamp_difference(bioname, userID):\n",
    "    videoT = get_video_timestamp(userID)\n",
    "    print(videoT)\n",
    "    filepath = USER_ROOT + bioname + \".json\"\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    bioT = float(data[\"timestamp\"])\n",
    "    difference = int(videoT) - int(bioT)\n",
    "    return difference\n",
    "    \n",
    "# print(timestamp_difference(\"EDA\", 25))\n",
    "# print(timestamp_difference(\"HR\", 25))\n",
    "\n",
    "# A more general function of the above\n",
    "def time_difference(videoT, bioname, userID):\n",
    "    filepath = USER_ROOT + bioname + \".json\"\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    bioT = float(data[\"timestamp\"])\n",
    "    difference = int(videoT) - int(bioT)\n",
    "    return difference\n",
    "\n",
    "\n",
    "# Get the sampling frequency of this particular biodata\n",
    "def get_frequency(bioname):\n",
    "    filepath = USER_ROOT + bioname + \".json\"\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    frequency = int(float(data[\"sampling_frequency\"]))\n",
    "    return frequency\n",
    "\n",
    "# Now calculate how much to index into the data array of biosignal json object to get matching data\n",
    "def get_beginning_index(bioname, userID):\n",
    "    difference = timestamp_difference(bioname, userID)\n",
    "    frequency = get_frequency(bioname)\n",
    "    return difference * frequency\n",
    "\n",
    "# A more general function of the above\n",
    "def get_adjusted_index(videoT, bioname, userID):\n",
    "    difference = time_difference(videoT, bioname, userID)\n",
    "    frequency = get_frequency(bioname)\n",
    "    #print(frequency)\n",
    "    #print(difference)\n",
    "    return difference * frequency\n",
    "\n",
    "# add spliced data to the biosignal json object\n",
    "def add_spliced_data_to_json(bioname, startIndex):\n",
    "    filepath = USER_ROOT + bioname + \".json\"\n",
    "    with open(filepath) as f:\n",
    "        data = json.load(f)\n",
    "    data[\"spliced_data\"] = data[\"data\"][startIndex:]\n",
    "    # rewrite this dictionary back to json file\n",
    "    save_jsonfile(filepath, data)\n",
    "    \n",
    "# Converts \"HH:mm:ss.S\" to number of seconds\n",
    "def elapsed_to_seconds(elapsed):\n",
    "    hour = 0\n",
    "    minute = 0\n",
    "    second = 0\n",
    "    result = 0\n",
    "    if len(elapsed) > 7:\n",
    "        hour = int(elapsed[:2])\n",
    "        minute = int(elapsed[3:5])\n",
    "        second = int(elapsed[6:8])\n",
    "        result = hour * 60 * 60 + minute * 60 + second\n",
    "    else:\n",
    "        minute = int(elapsed[:2])\n",
    "        second = int(elapsed[3:5])\n",
    "        result = minute * 60 + second\n",
    "    return result\n",
    "    \n",
    "# Calculate average biosignal during stage\n",
    "def average(bioname, stage, userID):\n",
    "    file = CODED_ROOT + \"25-\" + stage + \".csv\"\n",
    "    bio_filepath = USER_ROOT + bioname + \".json\"\n",
    "    videoT = get_video_timestamp(userID)\n",
    "    begin = 0\n",
    "    end = 0\n",
    "    spliced_data = []\n",
    "    with open(file) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader) # pass the headings       \n",
    "        for times in csvreader:\n",
    "            begin = times[2]\n",
    "            end = times[3]\n",
    "            begin = elapsed_to_seconds(begin)\n",
    "            end = elapsed_to_seconds(end)\n",
    "            vT_begin = videoT + begin\n",
    "            vT_end = videoT + end\n",
    "            index_begin = get_adjusted_index(vT_begin, bioname, userID)\n",
    "            index_end = get_adjusted_index(vT_end, bioname, userID)\n",
    "            with open(bio_filepath) as bf:\n",
    "                data = json.load(bf)\n",
    "            for item in data[\"data\"][index_begin:index_end]: # possibly need to add 1? Figure out\n",
    "                # need to convert spliced data into a list of ints instead of strings\n",
    "                spliced_data.append(item)\n",
    "    spliced_data = list(map(float, spliced_data))\n",
    "    count = len(spliced_data)\n",
    "    result = sum(spliced_data)/count\n",
    "    return result\n",
    "\n",
    "# testing for heart rate of getting started\n",
    "HR_GETSTART = average(\"HR\", \"Getting Started\", 25)\n",
    "EDA_GETSTART = average(\"EDA\", \"Getting Started\", 25)\n",
    "HR_SUCCESS = average(\"HR\", \"Success\", 25)\n",
    "EDA_SUCCESS = average(\"EDA\", \"Success\", 25)\n",
    "HR_ENCOUNTERDIFF = average(\"HR\", \"Encountering Difficulties\", 25)\n",
    "EDA_ENCOUNTERDIFF = average(\"EDA\", \"Encountering Difficulties\", 25)\n",
    "HR_DEALDIFF = average(\"HR\", \"Dealing with Difficulties\", 25)\n",
    "EDA_DEALDIFF = average(\"EDA\", \"Dealing with Difficulties\", 25)\n",
    "\n",
    "print(\"Average HR for Getting Started:\")\n",
    "print(HR_GETSTART)\n",
    "print(\"Average EDA for Getting Started:\")\n",
    "print(EDA_GETSTART)\n",
    "print(\"Average HR for Success:\")\n",
    "print(HR_SUCCESS)\n",
    "print(\"Average EDA for Success:\")\n",
    "print(EDA_SUCCESS)  \n",
    "print(\"Average HR for Encountering Difficulties:\")\n",
    "print(HR_ENCOUNTERDIFF)\n",
    "print(\"Average EDA for Encountering Difficulties:\")\n",
    "print(EDA_ENCOUNTERDIFF)\n",
    "print(\"Average HR for Dealing with Difficulties:\")\n",
    "print(HR_DEALDIFF)\n",
    "print(\"Average EDA for Dealing with Difficulties:\")\n",
    "print(EDA_DEALDIFF)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finer Biosignal Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate \"cropped\" biosignal csv files for each biosignal at each stage. There should be 8 biosignal files as of now generated. \n",
    "\n",
    "\n",
    "Naming convention:\n",
    "\n",
    "GS - Getting Started\n",
    "\n",
    "S - Success\n",
    "\n",
    "ED - Encountering Difficulties\n",
    "\n",
    "DD - Dealing with Difficulties\n",
    "\n",
    "e.g: ED_HR.csv, ED_EDA.csv\n",
    "\n",
    "The csv files will have a single column of all the biosignal measures during the specific stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CROPPED_ROOT = \"data/cropped/\"\n",
    "def generate_csv_at_cropped(filename, mylist):\n",
    "    name = CROPPED_ROOT + filename + \".csv\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        wr = csv.writer(csvfile)\n",
    "        for v in mylist:\n",
    "            wr.writerow([v])\n",
    "\n",
    "def shorten(stage):\n",
    "    if stage == \"Getting Started\":\n",
    "        return \"GS\"\n",
    "    elif stage == \"Success\":\n",
    "        return \"S\"\n",
    "    elif stage == \"Encountering Difficulties\":\n",
    "        return \"ED\"\n",
    "    elif stage == \"Dealing with Difficulties\":\n",
    "        return \"DD\"\n",
    "    else:\n",
    "        print(\"No match for this stage.\")\n",
    "\n",
    "def splice(bioname, stage, userID):\n",
    "    file = CODED_ROOT + \"25-\" + stage + \".csv\"\n",
    "    bio_filepath = USER_ROOT + bioname + \".json\"\n",
    "    videoT = get_video_timestamp(userID)\n",
    "    begin = 0\n",
    "    end = 0\n",
    "    spliced_data = []\n",
    "    with open(file) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader) # pass the headings       \n",
    "        for times in csvreader:\n",
    "            begin = times[2]\n",
    "            end = times[3]\n",
    "            begin = elapsed_to_seconds(begin)\n",
    "            end = elapsed_to_seconds(end)\n",
    "            vT_begin = videoT + begin\n",
    "            vT_end = videoT + end\n",
    "            index_begin = get_adjusted_index(vT_begin, bioname, userID)\n",
    "            index_end = get_adjusted_index(vT_end, bioname, userID)\n",
    "            with open(bio_filepath) as bf:\n",
    "                data = json.load(bf)\n",
    "            for item in data[\"data\"][index_begin:index_end]: # possibly need to add 1? Figure out\n",
    "                # need to convert spliced data into a list of ints instead of strings\n",
    "                spliced_data.append(item)\n",
    "    spliced_data = list(map(float, spliced_data))\n",
    "    #print(spliced_data)\n",
    "    shortened = shorten(stage)\n",
    "    filename = shortened + \"_\" + bioname\n",
    "    generate_csv_at_cropped(filename, spliced_data)\n",
    "    \n",
    "splice(\"HR\", \"Encountering Difficulties\", 25)\n",
    "splice(\"EDA\", \"Encountering Difficulties\", 25)\n",
    "splice(\"HR\", \"Getting Started\", 25)\n",
    "splice(\"EDA\", \"Getting Started\", 25)\n",
    "splice(\"HR\", \"Success\", 25)\n",
    "splice(\"EDA\", \"Success\", 25)\n",
    "splice(\"HR\", \"Dealing with Difficulties\", 25)\n",
    "splice(\"EDA\", \"Dealing with Difficulties\", 25)\n",
    "\n",
    "\n",
    "# generate_csv_at_cropped(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Tau Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average HR for Getting Started:\n",
      "70.42018691588785\n",
      "Average EDA for Getting Started:\n",
      "2.172140256425234\n",
      "Average HR for Success:\n",
      "97.45864864864866\n",
      "Average EDA for Success:\n",
      "2.8615414493243243\n",
      "Average HR for Encountering Difficulties:\n",
      "108.91074074074078\n",
      "Average EDA for Encountering Difficulties:\n",
      "2.997055990740741\n",
      "Average HR for Dealing with Difficulties:\n",
      "94.45558394160587\n",
      "Average EDA for Dealing with Difficulties:\n",
      "2.9017885857664303\n"
     ]
    }
   ],
   "source": [
    "TAU = 18\n",
    "# Calculate average biosignal during stage, but delayed by TAU seconds\n",
    "def average_shifted(bioname, stage, userID):\n",
    "    file = CODED_ROOT + \"25-\" + stage + \".csv\"\n",
    "    bio_filepath = USER_ROOT + bioname + \".json\"\n",
    "    videoT = get_video_timestamp(userID)\n",
    "    begin = 0\n",
    "    end = 0\n",
    "    spliced_data = []\n",
    "    with open(file) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader) # pass the headings       \n",
    "        for times in csvreader:\n",
    "            begin = times[2]\n",
    "            end = times[3]\n",
    "            begin = elapsed_to_seconds(begin) + TAU\n",
    "            end = elapsed_to_seconds(end) + TAU\n",
    "            vT_begin = videoT + begin\n",
    "            vT_end = videoT + end\n",
    "            index_begin = get_adjusted_index(vT_begin, bioname, userID)\n",
    "            index_end = get_adjusted_index(vT_end, bioname, userID)\n",
    "            with open(bio_filepath) as bf:\n",
    "                data = json.load(bf)\n",
    "            for item in data[\"data\"][index_begin:index_end]: # possibly need to add 1? Figure out\n",
    "                # need to convert spliced data into a list of ints instead of strings\n",
    "                spliced_data.append(item)\n",
    "    spliced_data = list(map(float, spliced_data))\n",
    "    count = len(spliced_data)\n",
    "    result = sum(spliced_data)/count\n",
    "    return result\n",
    "\n",
    "HR_GETSTART_S = average_shifted(\"HR\", \"Getting Started\", 25)\n",
    "EDA_GETSTART_S = average_shifted(\"EDA\", \"Getting Started\", 25)\n",
    "HR_SUCCESS_S = average_shifted(\"HR\", \"Success\", 25)\n",
    "EDA_SUCCESS_S = average_shifted(\"EDA\", \"Success\", 25)\n",
    "HR_ENCOUNTERDIFF_S = average_shifted(\"HR\", \"Encountering Difficulties\", 25)\n",
    "EDA_ENCOUNTERDIFF_S = average_shifted(\"EDA\", \"Encountering Difficulties\", 25)\n",
    "HR_DEALDIFF_S = average_shifted(\"HR\", \"Dealing with Difficulties\", 25)\n",
    "EDA_DEALDIFF_S = average_shifted(\"EDA\", \"Dealing with Difficulties\", 25)\n",
    "print(\"Average HR for Getting Started:\")\n",
    "print(HR_GETSTART_S)\n",
    "print(\"Average EDA for Getting Started:\")\n",
    "print(EDA_GETSTART_S)\n",
    "print(\"Average HR for Success:\")\n",
    "print(HR_SUCCESS_S)\n",
    "print(\"Average EDA for Success:\")\n",
    "print(EDA_SUCCESS_S)  \n",
    "print(\"Average HR for Encountering Difficulties:\")\n",
    "print(HR_ENCOUNTERDIFF_S)\n",
    "print(\"Average EDA for Encountering Difficulties:\")\n",
    "print(EDA_ENCOUNTERDIFF_S)\n",
    "print(\"Average HR for Dealing with Difficulties:\")\n",
    "print(HR_DEALDIFF_S)\n",
    "print(\"Average EDA for Dealing with Difficulties:\")\n",
    "print(EDA_DEALDIFF_S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tau value experiment 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TAU_ROOT = \"data/TAU/\"\n",
    "def generate_csv_at_TAU(filename, mylist):\n",
    "    name = TAU_ROOT + filename + \".csv\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        wr = csv.writer(csvfile)\n",
    "        for v in mylist:\n",
    "            wr.writerow([v])\n",
    "\n",
    "def splice_TAU(bioname, stage, userID):\n",
    "    file = CODED_ROOT + \"25-\" + stage + \".csv\"\n",
    "    bio_filepath = USER_ROOT + bioname + \".json\"\n",
    "    videoT = get_video_timestamp(userID)\n",
    "    begin = 0\n",
    "    end = 0\n",
    "    index = 0\n",
    "    spliced_data = []\n",
    "    with open(file) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader) # pass the headings       \n",
    "        for times in csvreader:\n",
    "            begin = times[2]\n",
    "            end = times[3]\n",
    "            begin = elapsed_to_seconds(begin)\n",
    "            end = elapsed_to_seconds(end)\n",
    "            vT_begin = videoT + begin - 5 # Want to see the previous 5 seconds of the biosignal prior to stimulus\n",
    "            vT_end = videoT + end\n",
    "            index_begin = get_adjusted_index(vT_begin, bioname, userID)\n",
    "            index_end = get_adjusted_index(vT_end, bioname, userID)\n",
    "            with open(bio_filepath) as bf:\n",
    "                data = json.load(bf)\n",
    "            for item in data[\"data\"][index_begin:index_end]: # possibly need to add 1? Figure out\n",
    "                # need to convert spliced data into a list of ints instead of strings\n",
    "                spliced_data.append(item)\n",
    "            # for every occurence of encountering difficulties, make a csv file of biosignals around that timestamp\n",
    "            spliced_data = list(map(float, spliced_data))\n",
    "            shortened = shorten(stage)\n",
    "            filename = shortened + \"_\" + bioname + \"_\" + str(index)\n",
    "            generate_csv_at_TAU(filename, spliced_data)\n",
    "            # increment index, restore spliced_data array\n",
    "            index += 1\n",
    "            spliced_data = []\n",
    "\n",
    "splice_TAU(\"EDA\",\"Encountering Difficulties\", 25 )\n",
    "splice_TAU(\"HR\",\"Encountering Difficulties\", 25 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
